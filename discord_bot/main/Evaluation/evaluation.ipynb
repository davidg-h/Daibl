{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einleitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook vergleichen wir verschiedene Ansätze, um sicherzustellen, dass unser Bot die am besten passenden Antworten generiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die 5 Fragen, die verglichen sollen folgende Eigenschaften besitzen:\n",
    "- Die Fragen sollen Fakultät übergreifend sein\n",
    "- Die Fragen sollen TH-spezifisch sein\n",
    "- Die Fragen sollen TH-Intranet-spezifisch sein\n",
    "- Die Fragen sollen Realitätsnah sein\n",
    "\n",
    "Die 5 Fragen, die verglichen werden sind:\n",
    "\n",
    "1. Wie ist die Email Adresse von Professor Gallwitz?\n",
    "2. Was soll ich beachten, wenn ich eine Prüfung anmelden will?\n",
    "3. Welche voraussetzungen, muss ich für den Mater Studiengang erfüllen?\n",
    "4. Welche Professoren gibt es an der Fakultät Soziale Arbeit?\n",
    "5. Wann und was muss ich im IT-Projekt machen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Model: Vicuna groß"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun werden fogende Parameter verglichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LLM Modell    | Kontext Variation | Word Embedding Model | Frage 1 | Antwort 1 | Frage 2 | Antwort 2 | Frage 3 | Antwort 3 | Frage 4 | Antwort 4 | Frage 5 | Antwort 5 | Durchschnitt |\n",
    "|---------------|-------------------|----------------------|---------|-----------|---------|-----------|---------|-----------|---------|-----------|---------|-----------|--------------|\n",
    "| Vicuna groß   | 1 Dokument        | a(MiniLM)            | 2       |           | 4       |           | 5       |           | 8       |           | 7       |           | 5.2          |\n",
    "| Vicuna groß   | 1 Dokument        | b(xy)                 | 10      |           | 10      |           | 10      |           | 10      |           | 10      |           | 10           |\n",
    "| Vicuna groß   | 1 Dokument        | c(TF-IDF)             |         |           |         |           |         |           |         |           |         |           | 0            |\n",
    "| Vicuna groß   | 1 Dokument        | d(MiniLM*TF-IDF)      |         |           |         |           |         |           |         |           |         |           | 0            |\n",
    "| Vicuna groß   | 1 Dokument        | e(xy*TF-IDF)          |         |           |         |           |         |           |         |           |         |           | 0            |\n",
    "| Vicuna groß   | 5 Dokumente       | a                     |         |           |         |           |         |           |         |           |         |           | 0            |\n",
    "| Vicuna groß   | 5 Dokumente       | b                     |         |           |         |           |         |           |         |           |         |           | 0            |\n",
    "| Vicuna groß   | 5 Dokumente       | c                     |         |           |         |           |         |           |         |           |         |           | 0            |\n",
    "| Vicuna groß   | 5 Dokumente       | d                     |         |           |         |           |         |           |         |           |         |           | 0            |\n",
    "| Vicuna groß   | 5 Dokumente       | e                     |         |           |         |           |         |           |         |           |         |           | 0            |\n",
    "| Vicuna groß   | 10 Dokumente      | a                     |         |           |         |           |         |           |         |           |         |           | 0            |\n",
    "| Vicuna groß   | 10 Dokumente      | b                     |         |           |         |           |         |           |         |           |         |           | 0            |\n",
    "| Vicuna groß   | 10 Dokumente      | c                     |         |           |         |           |         |           |         |           |         |           | 0            |\n",
    "| Vicuna groß   | 10 Dokumente      | d                     |         |           |         |           |         |           |         |           |         |           | 0            |\n",
    "| Vicuna groß   | 10 Dokumente      | e                     |         |           |         |           |         |           |         |           |         |           | 0            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun soll ein script ersteltt werden, der die Antwort Spalten generiert.\n",
    "Nacher werden die Antworten manuell bewertet von allen Projekt Teilnehmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "from scrap.query_crafter import construct_prompt\n",
    "from scrap.embedding_algorithms.tdIdfDistance import get_most_similar_articles_tf_idf\n",
    "from scrap.embedding_algorithms.question_embedding_MiniLM import get_most_similar_articles_MiniLM\n",
    "from LLM.ServerCommunicator import server_get_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar_articles_for_specified_embediing_model(embedding_model,question,document_amount):\n",
    "    \n",
    "    embeddings_model_dict = {\n",
    "        'MiniLM': get_most_similar_articles_MiniLM,\n",
    "        'TF-IDF': get_most_similar_articles_tf_idf\n",
    "    }\n",
    "     \n",
    "    get_most_similar_articles = embeddings_model_dict.get(embedding_model)\n",
    "    result = get_most_similar_articles(question,document_amount)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_anwser_from_model(model_id,prompt):\n",
    "\n",
    "    model_dict = {\n",
    "        'vicuna_70b': server_get_answer,\n",
    "        'vicuna_13b': get_most_similar_articles_tf_idf,\n",
    "        'llama_13b': get_most_similar_articles_tf_idf\n",
    "\n",
    "    }\n",
    "    get_anwser = model_dict.get(model_id)\n",
    "    anwser = await get_anwser(prompt)\n",
    "\n",
    "    return anwser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to forward the port for the vicuna_70b model.\n",
    "To do so, copy the template into the terminal:  ssh -N -L localhost:8080:localhost:8087 <musterm123>@141.75.89.6 and enter your password afterwards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_response(model_id,document_amount,embedding_model,question):\n",
    "    anwser=\"\"\n",
    "    documents = get_most_similar_articles_for_specified_embediing_model(embedding_model,question,document_amount)\n",
    "    prompt = construct_prompt(documents, question) \n",
    "    anwser = await get_anwser_from_model(model_id,prompt)\n",
    "    \n",
    "    return anwser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models= [\"vicuna_70b\",\"vicuna_13b\",\"llama_13b\"]\n",
    "document_amounts=[1,5,10]\n",
    "embeddings_models=[\"MiniLM\",\"TF-IDF\"]\n",
    "questions=[\"Wie ist die Email Adresse von Professor Gallwitz?\",\n",
    "           \"Was soll ich beachten, wenn ich eine Prüfung anmelden will?\",\n",
    "           \"Welche voraussetzungen, muss ich für den Mater Studiengang erfüllen?\",\n",
    "           \"Welche Professoren gibt es an der Fakultät Soziale Arbeit?\",\n",
    "           \"Wann und was muss ich im IT-Projekt machen?\"]\n",
    "\n",
    "for model_id in models:\n",
    "    for document_amount in document_amounts:\n",
    "        for embeddings_model in embeddings_models:\n",
    "            for question in questions:\n",
    "                response = generate_response(model_id, document_amount, embeddings_model, question)\n",
    "                print(f\"Model: {model_id}, Docs: {document_amount}, Embeddings: {embeddings_model}, Question: {question}\")\n",
    "                print(f\"Response: {response}\")\n",
    "                print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await generate_response(\"vicuna_70b\",1,\"MiniLM\",\"Wie ist die Email Adresse von Professor Gallwitz?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Geben Sie den Dateipfad zu Ihrer Excel-Datei an\n",
    "excel_file_path = 'C:\\\\Users\\\\lizab\\\\Desktop\\\\TH\\\\Semester6\\\\ItProjekt\\\\Evaluation.xlsx'\n",
    "\n",
    "# Laden Sie die Excel-Datei in einen Pandas DataFrame\n",
    "df = pd.read_excel(excel_file_path, sheet_name='Sheet1')\n",
    "\n",
    "# Modifizieren Sie die Zellen nach Bedarf\n",
    "# Beispiel: Setzen Sie den Wert 42 in die Zelle in der ersten Zeile und ersten Spalte\n",
    "df.at[0, 'Spaltenname'] = \"halloichbins\"\n",
    "\n",
    "# Speichern Sie die Änderungen zurück in die Excel-Datei\n",
    "df.to_excel(excel_file_path, sheet_name='Sheet1', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Erstellen Sie eine leere DataFrame\n",
    "columns = [\"Model\", \"Document Amount\", \"Embeddings Model\", \"Question\", \"Response\"]\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Ihre Daten\n",
    "models = [\"vicuna_70b\"]\n",
    "document_amounts = [1, 5, 10]\n",
    "embeddings_models=[\"MiniLM\",\"TF-IDF\"]\n",
    "questions=[\"Wie ist die Email Adresse von Professor Gallwitz?\",\n",
    "           \"Was soll ich beachten, wenn ich eine Prüfung anmelden will?\",\n",
    "           \"Welche voraussetzungen, muss ich für den Mater Studiengang erfüllen?\",\n",
    "           \"Welche Professoren gibt es an der Fakultät Soziale Arbeit?\",\n",
    "           \"Wann und was muss ich im IT-Projekt machen?\"]\n",
    "\n",
    "data = []\n",
    "for model in models:\n",
    "    for document_amount in document_amounts:\n",
    "        for embeddings_model in embeddings_models:\n",
    "            for question in questions:\n",
    "                response = await generate_response(model, document_amount, embeddings_model, question)\n",
    "                data.append([model, document_amount, embeddings_model, question, response])\n",
    "\n",
    "df = pd.concat([df, pd.DataFrame(data, columns=columns)], ignore_index=True)\n",
    "\n",
    "# Speichern Sie die DataFrame in eine Excel-Datei\n",
    "df.to_excel('output.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
